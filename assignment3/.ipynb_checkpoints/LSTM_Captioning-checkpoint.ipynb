{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning with LSTMs\n",
    "In the previous exercise you implemented a vanilla RNN and applied it to image captioning. In this notebook you will implement the LSTM update rule and use it for image captioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.rnn_layers import *\n",
    "from cs231n.captioning_solver import CaptioningSolver\n",
    "from cs231n.classifiers.rnn import CaptioningRNN\n",
    "from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from cs231n.image_utils import image_from_url\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MS-COCO data\n",
    "As in the previous notebook, we will use the Microsoft COCO dataset for captioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_to_word <type 'list'> 1004\n",
      "train_captions <type 'numpy.ndarray'> (400135, 17) int32\n",
      "val_captions <type 'numpy.ndarray'> (195954, 17) int32\n",
      "train_image_idxs <type 'numpy.ndarray'> (400135,) int32\n",
      "val_features <type 'numpy.ndarray'> (40504, 512) float32\n",
      "val_image_idxs <type 'numpy.ndarray'> (195954,) int32\n",
      "train_features <type 'numpy.ndarray'> (82783, 512) float32\n",
      "train_urls <type 'numpy.ndarray'> (82783,) |S63\n",
      "val_urls <type 'numpy.ndarray'> (40504,) |S63\n",
      "word_to_idx <type 'dict'> 1004\n"
     ]
    }
   ],
   "source": [
    "# Load COCO data from disk; this returns a dictionary\n",
    "# We'll work with dimensionality-reduced features for this notebook, but feel\n",
    "# free to experiment with the original features by changing the flag below.\n",
    "data = load_coco_data(pca_features=True)\n",
    "\n",
    "# Print out all the keys and values from the data dictionary\n",
    "for k, v in data.iteritems():\n",
    "  if type(v) == np.ndarray:\n",
    "    print k, type(v), v.shape, v.dtype\n",
    "  else:\n",
    "    print k, type(v), len(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "If you read recent papers, you'll see that many people use a variant on the vanialla RNN called Long-Short Term Memory (LSTM) RNNs. Vanilla RNNs can be tough to train on long sequences due to vanishing and exploding gradiants caused by repeated matrix multiplication. LSTMs solve this problem by replacing the simple update rule of the vanilla RNN with a gating mechanism as follows.\n",
    "\n",
    "Similar to the vanilla RNN, at each timestep we receive an input $x_t\\in\\mathbb{R}^D$ and the previous hidden state $h_{t-1}\\in\\mathbb{R}^H$; the LSTM also maintains an $H$-dimensional *cell state*, so we also receive the previous cell state $c_{t-1}\\in\\mathbb{R}^H$. The learnable parameters of the LSTM are an *input-to-hidden* matrix $W_x\\in\\mathbb{R}^{4H\\times D}$, a *hidden-to-hidden* matrix $W_h\\in\\mathbb{R}^{4H\\times H}$ and a *bias vector* $b\\in\\mathbb{R}^{4H}$.\n",
    "\n",
    "At each timestep we first compute an *activation vector* $a\\in\\mathbb{R}^{4H}$ as $a=W_xx_t + W_hh_{t-1}+b$. We then divide this into four vectors $a_i,a_f,a_o,a_g\\in\\mathbb{R}^H$ where $a_i$ consists of the first $H$ elements of $a$, $a_f$ is the next $H$ elements of $a$, etc. We then compute the *input gate* $g\\in\\mathbb{R}^H$, *forget gate* $f\\in\\mathbb{R}^H$, *output gate* $o\\in\\mathbb{R}^H$ and *block input* $g\\in\\mathbb{R}^H$ as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "i = \\sigma(a_i) \\hspace{2pc}\n",
    "f = \\sigma(a_f) \\hspace{2pc}\n",
    "o = \\sigma(a_o) \\hspace{2pc}\n",
    "g = \\tanh(a_g)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the sigmoid function and $\\tanh$ is the hyperbolic tangent, both applied elementwise.\n",
    "\n",
    "Finally we compute the next cell state $c_t$ and next hidden state $h_t$ as\n",
    "\n",
    "$$\n",
    "c_{t} = f\\odot c_{t-1} + i\\odot g \\hspace{4pc}\n",
    "h_t = o\\odot\\tanh(c_t)\n",
    "$$\n",
    "\n",
    "where $\\odot$ is the elementwise product of vectors.\n",
    "\n",
    "In the rest of the notebook we will implement the LSTM update rule and apply it to the image captioning task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: step forward\n",
    "Implement the forward pass for a single timestep of an LSTM in the `lstm_step_forward` function in the file `cs231n/rnn_layers.py`. This should be similar to the `rnn_step_forward` function that you implemented above, but using the LSTM update rule instead.\n",
    "\n",
    "Once you are done, run the following to perform a simple test of your implementation. You should see errors around `1e-8` or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_h error:  5.70541304045e-09\n",
      "next_c error:  5.81431230888e-09\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 3, 4, 5\n",
    "x = np.linspace(-0.4, 1.2, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.3, 0.7, num=N*H).reshape(N, H)\n",
    "prev_c = np.linspace(-0.4, 0.9, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-2.1, 1.3, num=4*D*H).reshape(D, 4 * H)\n",
    "Wh = np.linspace(-0.7, 2.2, num=4*H*H).reshape(H, 4 * H)\n",
    "b = np.linspace(0.3, 0.7, num=4*H)\n",
    "\n",
    "next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)\n",
    "\n",
    "expected_next_h = np.asarray([\n",
    "    [ 0.24635157,  0.28610883,  0.32240467,  0.35525807,  0.38474904],\n",
    "    [ 0.49223563,  0.55611431,  0.61507696,  0.66844003,  0.7159181 ],\n",
    "    [ 0.56735664,  0.66310127,  0.74419266,  0.80889665,  0.858299  ]])\n",
    "expected_next_c = np.asarray([\n",
    "    [ 0.32986176,  0.39145139,  0.451556,    0.51014116,  0.56717407],\n",
    "    [ 0.66382255,  0.76674007,  0.87195994,  0.97902709,  1.08751345],\n",
    "    [ 0.74192008,  0.90592151,  1.07717006,  1.25120233,  1.42395676]])\n",
    "\n",
    "print 'next_h error: ', rel_error(expected_next_h, next_h)\n",
    "print 'next_c error: ', rel_error(expected_next_c, next_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LSTM: step backward\n",
    "Implement the backward pass for a single LSTM timestep in the function `lstm_step_backward` in the file `cs231n/rnn_layers.py`. Once you are done, run the following to perform numeric gradient checking on your implementation. You should see errors around `1e-8` or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  2.52467901143e-09\n",
      "dh error:  1.34483589333e-10\n",
      "dc error:  1.59955652938e-10\n",
      "dWx error:  4.49107724923e-08\n",
      "dWh error:  3.63923399663e-09\n",
      "db error:  5.48273877362e-10\n"
     ]
    }
   ],
   "source": [
    "N, D, H = 4, 5, 6\n",
    "x = np.random.randn(N, D)\n",
    "prev_h = np.random.randn(N, H)\n",
    "prev_c = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, 4 * H)\n",
    "Wh = np.random.randn(H, 4 * H)\n",
    "b = np.random.randn(4 * H)\n",
    "\n",
    "next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)\n",
    "\n",
    "dnext_h = np.random.randn(*next_h.shape)\n",
    "dnext_c = np.random.randn(*next_c.shape)\n",
    "\n",
    "fx_h = lambda x: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fh_h = lambda h: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fc_h = lambda c: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fWx_h = lambda Wx: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fWh_h = lambda Wh: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "fb_h = lambda b: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n",
    "\n",
    "fx_c = lambda x: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fh_c = lambda h: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fc_c = lambda c: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fWx_c = lambda Wx: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fWh_c = lambda Wh: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "fb_c = lambda b: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n",
    "\n",
    "num_grad = eval_numerical_gradient_array\n",
    "\n",
    "dx_num = num_grad(fx_h, x, dnext_h) + num_grad(fx_c, x, dnext_c)\n",
    "dh_num = num_grad(fh_h, prev_h, dnext_h) + num_grad(fh_c, prev_h, dnext_c)\n",
    "dc_num = num_grad(fc_h, prev_c, dnext_h) + num_grad(fc_c, prev_c, dnext_c)\n",
    "dWx_num = num_grad(fWx_h, Wx, dnext_h) + num_grad(fWx_c, Wx, dnext_c)\n",
    "dWh_num = num_grad(fWh_h, Wh, dnext_h) + num_grad(fWh_c, Wh, dnext_c)\n",
    "db_num = num_grad(fb_h, b, dnext_h) + num_grad(fb_c, b, dnext_c)\n",
    "\n",
    "dx, dh, dc, dWx, dWh, db = lstm_step_backward(dnext_h, dnext_c, cache)\n",
    "\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dh error: ', rel_error(dh_num, dh)\n",
    "print 'dc error: ', rel_error(dc_num, dc)\n",
    "print 'dWx error: ', rel_error(dWx_num, dWx)\n",
    "print 'dWh error: ', rel_error(dWh_num, dWh)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: forward\n",
    "In the function `lstm_forward` in the file `cs231n/rnn_layers.py`, implement the `lstm_forward` function to run an LSTM forward on an entire timeseries of data.\n",
    "\n",
    "When you are done run the following to check your implementation. You should see an error around `1e-7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h error:  8.61053745211e-08\n"
     ]
    }
   ],
   "source": [
    "N, D, H, T = 2, 5, 4, 3\n",
    "x = np.linspace(-0.4, 0.6, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.4, 0.8, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.2, 0.9, num=4*D*H).reshape(D, 4 * H)\n",
    "Wh = np.linspace(-0.3, 0.6, num=4*H*H).reshape(H, 4 * H)\n",
    "b = np.linspace(0.2, 0.7, num=4*H)\n",
    "\n",
    "h, cache = lstm_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "expected_h = np.asarray([\n",
    " [[ 0.01764008,  0.01823233,  0.01882671,  0.0194232 ],\n",
    "  [ 0.11287491,  0.12146228,  0.13018446,  0.13902939],\n",
    "  [ 0.31358768,  0.33338627,  0.35304453,  0.37250975]],\n",
    " [[ 0.45767879,  0.4761092,   0.4936887,   0.51041945],\n",
    "  [ 0.6704845,   0.69350089,  0.71486014,  0.7346449 ],\n",
    "  [ 0.81733511,  0.83677871,  0.85403753,  0.86935314]]])\n",
    "\n",
    "print 'h error: ', rel_error(expected_h, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: backward\n",
    "Implement the backward pass for an LSTM over an entire timeseries of data in the function `lstm_backward` in the file `cs231n/rnn_layers.py`. When you are done run the following to perform numeric gradient checking on your implementation. You should see errors around `1e-8` or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  3.3566640737e-09\n",
      "dh0 error:  1.58221816078e-10\n",
      "dWx error:  5.67489495778e-09\n",
      "dWh error:  4.21083699673e-08\n",
      "db error:  5.05973989831e-09\n"
     ]
    }
   ],
   "source": [
    "from cs231n.rnn_layers import lstm_forward, lstm_backward\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 6\n",
    "\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, 4 * H)\n",
    "Wh = np.random.randn(H, 4 * H)\n",
    "b = np.random.randn(4 * H)\n",
    "\n",
    "out, cache = lstm_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "dout = np.random.randn(*out.shape)\n",
    "\n",
    "dx, dh0, dWx, dWh, db = lstm_backward(dout, cache)\n",
    "\n",
    "fx = lambda x: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fh0 = lambda h0: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "fb = lambda b: lstm_forward(x, h0, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dh0_num = eval_numerical_gradient_array(fh0, h0, dout)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dout)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dh0 error: ', rel_error(dh0_num, dh0)\n",
    "print 'dWx error: ', rel_error(dWx_num, dWx)\n",
    "print 'dWh error: ', rel_error(dWh_num, dWh)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LSTM captioning model\n",
    "Now that you have implemented an LSTM, update the implementation of the `loss` method of the `CaptioningRNN` class in the file `cs231n/classifiers/rnn.py` to handle the case where `self.cell_type` is `lstm`. This should require adding less than 10 lines of code.\n",
    "\n",
    "Once you have done so, run the following to check your implementation. You should see a difference of less than `1e-10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  9.82445935443\n",
      "expected loss:  9.82445935443\n",
      "difference:  2.26485497024e-12\n"
     ]
    }
   ],
   "source": [
    "N, D, W, H = 10, 20, 30, 40\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "V = len(word_to_idx)\n",
    "T = 13\n",
    "\n",
    "model = CaptioningRNN(word_to_idx,\n",
    "          input_dim=D,\n",
    "          wordvec_dim=W,\n",
    "          hidden_dim=H,\n",
    "          cell_type='lstm',\n",
    "          dtype=np.float64)\n",
    "\n",
    "# Set all model parameters to fixed values\n",
    "for k, v in model.params.iteritems():\n",
    "  model.params[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)\n",
    "\n",
    "features = np.linspace(-0.5, 1.7, num=N*D).reshape(N, D)\n",
    "captions = (np.arange(N * T) % V).reshape(N, T)\n",
    "\n",
    "loss, grads = model.loss(features, captions)\n",
    "expected_loss = 9.82445935443\n",
    "\n",
    "print 'loss: ', loss\n",
    "print 'expected loss: ', expected_loss\n",
    "print 'difference: ', abs(loss - expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit LSTM captioning model\n",
    "Run the following to overfit an LSTM captioning model on the same small dataset as we used for the RNN above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 100) loss: 78.576769\n",
      "(Iteration 11 / 100) loss: 41.998857\n",
      "(Iteration 21 / 100) loss: 26.024590\n",
      "(Iteration 31 / 100) loss: 18.108541\n",
      "(Iteration 41 / 100) loss: 6.558564\n",
      "(Iteration 51 / 100) loss: 2.663758\n",
      "(Iteration 61 / 100) loss: 1.402717\n",
      "(Iteration 71 / 100) loss: 0.612838\n",
      "(Iteration 81 / 100) loss: 0.378681\n",
      "(Iteration 91 / 100) loss: 0.225757\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAH4CAYAAAALn5onAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHQ+j1bvsvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x100e9cf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_data = load_coco_data(max_train=50)\n",
    "\n",
    "small_lstm_model = CaptioningRNN(\n",
    "          cell_type='lstm',\n",
    "          word_to_idx=data['word_to_idx'],\n",
    "          input_dim=data['train_features'].shape[1],\n",
    "          hidden_dim=512,\n",
    "          wordvec_dim=256,\n",
    "          dtype=np.float32,\n",
    "        )\n",
    "\n",
    "small_lstm_solver = CaptioningSolver(small_lstm_model, small_data,\n",
    "           update_rule='adam',\n",
    "           num_epochs=50,\n",
    "           batch_size=25,\n",
    "           optim_config={\n",
    "             'learning_rate': 5e-3,\n",
    "           },\n",
    "           lr_decay=0.995,\n",
    "           verbose=True, print_every=10,\n",
    "         )\n",
    "\n",
    "small_lstm_solver.train()\n",
    "\n",
    "# Plot the training losses\n",
    "plt.plot(small_lstm_solver.loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM test-time sampling\n",
    "Modify the `sample` method of the `CaptioningRNN` class to handle the case where `self.cell_type` is `lstm`. This should take fewer than 10 lines of code.\n",
    "\n",
    "When you are done run the following to sample from your overfit LSTM model on some training and validation set samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "[Errno 54] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9d69e78ce33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mgt_caption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_caption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s\\n%s\\nGT:%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_caption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_caption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/qq456cvb/Documents/Stanford/assignment3/cs231n/image_utils.pyc\u001b[0m in \u001b[0;36mimage_from_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \"\"\"\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 449\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# buffering kw not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self, buffering)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwill_close\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_UNKNOWN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CS_IDLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Initialize with Simple-Response defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: [Errno 54] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'val']:\n",
    "  minibatch = sample_coco_minibatch(small_data, split=split, batch_size=2)\n",
    "  gt_captions, features, urls = minibatch\n",
    "  gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "  sample_captions = small_lstm_model.sample(features)\n",
    "  sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "  for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "    plt.imshow(image_from_url(url))\n",
    "    plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a good captioning model!\n",
    "Using the pieces you have implemented in this and the previous notebook, try to train a captioning model that gives decent qualitative results (better than the random garbage you saw with the overfit models) when sampling on the validation set. You can subsample the training set if you want; we just want to see samples on the validatation set that are better than random.\n",
    "\n",
    "Don't spend too much time on this part; we don't have any explicit accuracy thresholds you need to meet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
